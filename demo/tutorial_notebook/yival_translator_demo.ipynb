{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Yival Translator Demo** üë®‚Äçüç≥üë©‚Äçüç≥\n",
        "Experience Yival's powerful features by build a cheap translator with GPT-4.\n",
        "\n",
        "Use Replicate and GPT-4's test data , you can **finetune** llama2's translation bot.\n",
        "\n",
        "Benefit from **18x** savings while experiencing only a **6%** performance decrease.\n",
        "\n",
        "We provide two way of yival finetune\n",
        "* Replicate api call\n",
        "* [SFT Trainer](https://github.com/YiVal/YiVal/blob/master/src/yival/finetune/sft_trainer.py)\n",
        "\n",
        "With Replicate , we only use 400 examples and finetuning with 10 epochs\n",
        "- bertscore-p 0.419 -> 0.445 (**+6.2%**)\n",
        "- bertscore-r 0.592 -> 0.611 (**+3.2%**)\n",
        "- bertscore-f 0.489 -> 0.514 (**+5.1%**)\n",
        "\n",
        "![image](https://github.com/crazycth/pictures/assets/55043304/898a8812-bbd9-4d3d-92fa-1a8c6b433e8c)\n",
        "\n",
        "We finetune our modal locally with [yival-sft-trainer](https://github.com/YiVal/YiVal/blob/add_conditioin_for_trainer/src/yival/finetune/sft_trainer.py) with 8 1080Ti and train for 8 hours on [EMNLP 2020 translation dataset](https://statmt.org/wmt20/translation-task.html).\n",
        "\n",
        "\n",
        "For the same 400 test data sample, we achieved much better performance.\n",
        "- bertscore-p 0.516 -> 0.835 (**+61.8%**)\n",
        "- bertscore-r 0.653 -> 0.828 (**+27.0%**)\n",
        "- bertscore-f 0.575 -> 0.831 (**+44.5%**)\n",
        "\n",
        "Also, we see after fine-tuning, our new llama2 model can achieve **comparable performance** as gpt-3.5.\n",
        "\n",
        "![**Model performance comparison**](https://github.com/KyleChen400/YiVal/assets/42785676/a62782d6-1523-408c-a5ce-f7069c720f68)\n",
        "\n",
        "### **What is YiVal?**\n",
        "> YiVal is a versatile platform support customize test data, evaluation methods and enhancement strategy , all in one.\n",
        "It enpowers you to generate better results, reduce latency and decrease inference cost.\n",
        "\n",
        "**~~TL~~DR**: YiVal streamlines the **evaluation** and **enhancement** of GenAI Apps, enhance ane evaluate **everything** with ease.\n",
        "\n",
        "### **Why YiVal**\n",
        "\n",
        "\n",
        "*   Native support **Multi-modal** apps: textüìÑ + audioüéô + imageüåÉ + videoüé•\n",
        "*   **Multi-components**: which doesn't even have to be GenAI üòÅ\n",
        "*   Native **RLHF** and **RLAIF** ‚öôÔ∏è\n",
        "*   Most advanced open source **enhancement algorithms** ü™Ñ\n",
        "\n",
        "### **Fine-tuning LLMs in YiVal**\n",
        "<img src=\"https://github.com/crazycth/pictures/assets/55043304/b59542de-911f-448b-9251-e054e2c71bdc\" alt=\"image\" style=\"max-width: 500px; max-height: 300px;\">\n"
      ],
      "metadata": {
        "id": "XnVflr_OGnVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install the latest yival with git**\n",
        "\n",
        "We provide two ways of yival install\n",
        "\n",
        "1. install with pip\n",
        "```\n",
        "pip install yival\n",
        "```\n",
        "\n",
        "2. Developer Mode: The latest yival\n",
        "```\n",
        "git clone https://github.com/YiVal/YiVal.git\n",
        "poetry config virtualenvs.create true\n",
        "poetry install\n",
        "```\n",
        "\n",
        "here we install with poetry , you can find the detail below\n",
        "* install poetry in colab environment\n",
        "* install yival with poetry"
      ],
      "metadata": {
        "id": "Wc-n2ifuOtqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the latest yival\n",
        "import os\n",
        "!python --version\n",
        "!rm -rf YiVal\n",
        "!git clone -b stable https://github.com/YiVal/YiVal.git\n",
        "\n",
        "# install and config poetry\n",
        "import shutil\n",
        "!pip install poetry\n",
        "POETRY_PATH = shutil.which(\"poetry\") or (os.getenv(\"HOME\") + \"/.local/bin/poetry\")\n",
        "os.environ[\"PATH\"] += os.pathsep + os.path.dirname(POETRY_PATH)\n",
        "!poetry --version\n",
        "!poetry config virtualenvs.create true"
      ],
      "metadata": {
        "id": "VokE5fiKMnUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/YiVal\")\n",
        "!poetry install --no-ansi"
      ],
      "metadata": {
        "id": "At-gZKAPOwzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "id": "O5Qz7kptT70I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configure your OpenAI API key**\n",
        "\n",
        "In yival, most of time we will use chatgpt as data_generator, evaluator , improver...\n",
        "\n",
        "It's really amazing to find that llm is so powerful\n",
        "\n",
        "In some of the demos provided by Yival, we use GPT-4 for data generation, result evaluation, and so on, because GPT-4 has stronger **reasoning** capabilities.\n"
      ],
      "metadata": {
        "id": "if49tVfLO7I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = ''"
      ],
      "metadata": {
        "id": "Kc6wBFJtO8ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configure your [replicate](https://replicate.com/) API key**\n",
        "\n",
        "we will use replicate to finetune llama2 for translation"
      ],
      "metadata": {
        "id": "CW4pwdVTO_BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['REPLICATE_API_TOKEN'] = ''"
      ],
      "metadata": {
        "id": "2SWgP8OMPHvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[Optional] Change gpt-4 to gpt-3.5-turbo in config**\n",
        "\n",
        "If you don't have a GPT-4 account, you can also use GPT-3.5-turbo to complete the entire process, you just need to modify the **model_name** in the config file.\n",
        "\n",
        "For example , you can find `model_name` below\n",
        "\n",
        "```yaml\n",
        "description: Generate standard translation data\n",
        "dataset:\n",
        "  data_generators:\n",
        "    openai_prompt_data_generator:\n",
        "      chunk_size: 100000\n",
        "      diversify: true\n",
        "      model_name: gpt-4 #Change the model_name to gpt-3.5-turbo here ü¶ÑÔ∏è\n",
        "      input_function:\n",
        "        description:\n",
        "          Given a tech startup business, generate a corresponding landing\n",
        "          page headline\n",
        "        name: headline_generation_for_business\n",
        "        parameters:\n",
        "          tech_startup_business: str\n",
        "      number_of_examples: 3\n",
        "      output_csv_path: generated_examples.csv\n",
        "  source_type: machine_generated\n",
        "```\n",
        "\n",
        "If you want to use gpt-3.5-turbo, change the `use_gpt_35_turbo` to `True` in the below cell and run it.\n",
        "\n",
        "It will autotimatically replace all `gpt-4` to `gpt-3.5-turbo` in all yamls provided by yival"
      ],
      "metadata": {
        "id": "OXwlvinwPnLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, yaml\n",
        "use_gpt_35_turbo = True  #change it to True if you don't want to use gpt-4\n",
        "\n",
        "def replace_gpt4_recursive(data):\n",
        "    if isinstance(data, str):\n",
        "        return data.replace('gpt-4', 'gpt-3.5-turbo')\n",
        "    elif isinstance(data, list):\n",
        "        return [replace_gpt4_recursive(item) for item in data]\n",
        "    elif isinstance(data, dict):\n",
        "        return {key: replace_gpt4_recursive(value) for key, value in data.items()}\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "\n",
        "def replace_in_yaml_files(directory):\n",
        "    for filename in glob.glob(os.path.join(directory, '*.yml')):\n",
        "        with open(filename, 'r') as file:\n",
        "            data = yaml.safe_load(file)\n",
        "        data = replace_gpt4_recursive(data)\n",
        "        with open(filename, 'w') as file:\n",
        "            yaml.safe_dump(data, file)\n",
        "\n",
        "if use_gpt_35_turbo:\n",
        "  replace_in_yaml_files(\"/content/YiVal/demo/configs\")\n",
        "  print(\"[INFO] replace all gpt-4 to gpt-3.5-turbo. Use gpt-3.5-turbo in the coming page\")\n",
        "else:\n",
        "  print(\"[INFO] use default gpt-4\")"
      ],
      "metadata": {
        "id": "1lK9nKXsPpWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **YiVal Finetune üê§TuToRiAlüê§**\n",
        "In this demo, we first used GPT-4 to generate some translation data and reference answers.\n",
        "\n",
        "Then, we tested the translation BertScore of gpt-3.5-turbo and llama2-13b.\n",
        "\n",
        "Finally, we performed finetuning on llama2 for translation using two different methods.\n",
        "1. replicate api finetune\n",
        "2. finetune locally with SFT-Trainer"
      ],
      "metadata": {
        "id": "p2ywT3-Qg05S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Generator**\n",
        "\n",
        "We will use GPT-4 to generate translation data.\n",
        "\n",
        "Here we use openai_prompt_data_generator to generate the input of our custoom function.\n",
        "\n",
        "```yaml\n",
        "description: Generated experiment config\n",
        "dataset:\n",
        "  data_generators:\n",
        "    openai_prompt_data_generator:\n",
        "      chunk_size: 100000\n",
        "      diversify: true\n",
        "      # model_name specify the llm model , e.g. a16z-infra/llama-2-13b-chat:9dff94b1bed5af738655d4a7cbcdcde2bd503aa85c94334fe1f42af7f3dd5ee3\n",
        "      model_name: gpt-4\n",
        "      prompt:\n",
        "          \"Please provide a concrete and realistic test case as a dictionary for function invocation using the ** operator.\n",
        "          Only include parameters, excluding description and name.\n",
        "          Ensure it's succinct and well-structured.\n",
        "          **Only provide the dictionary.**\"\n",
        "      input_function:\n",
        "        description:\n",
        "          The current function is to evaluate the English to Chinese translation ability of the large language model. You will play the role of a teacher, so please provide a coherent English sentence (teacher_quiz), and give the corresponding Chinese translation (teachaer_answer).\n",
        "        name: translation_english_to_chinese\n",
        "        parameters:\n",
        "          teacher_quiz: str\n",
        "          teacher_answer: str\n",
        "      expected_param_name: teacher_answer\n",
        "      number_of_examples: 2\n",
        "      output_csv_path: standard_data.csv\n",
        "      call_option:\n",
        "        temperature: 1.6\n",
        "        presence_penalty: 2\n",
        "  source_type: machine_generated\n",
        "  ```"
      ],
      "metadata": {
        "id": "5dEviKEgPNYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_content = '''\n",
        "description: Generated experiment config\n",
        "dataset:\n",
        "  data_generators:\n",
        "    openai_prompt_data_generator:\n",
        "      chunk_size: 100000\n",
        "      diversify: true\n",
        "      # model_name specify the llm model , e.g. a16z-infra/llama-2-13b-chat:9dff94b1bed5af738655d4a7cbcdcde2bd503aa85c94334fe1f42af7f3dd5ee3\n",
        "      model_name: gpt-4\n",
        "      prompt:\n",
        "          \"Please provide a concrete and realistic test case as a dictionary for function invocation using the ** operator.\n",
        "          Only include parameters, excluding description and name.\n",
        "          Ensure it's succinct and well-structured.\n",
        "          **Only provide the dictionary.**\"\n",
        "      input_function:\n",
        "        description:\n",
        "          The current function is to evaluate the English to Chinese translation ability of the large language model. You will play the role of a teacher, so please provide a coherent English sentence (teacher_quiz), and give the corresponding Chinese translation (teachaer_answer).\n",
        "        name: translation_english_to_chinese\n",
        "        parameters:\n",
        "          teacher_quiz: str\n",
        "          teacher_answer: str\n",
        "      expected_param_name: teacher_answer\n",
        "      number_of_examples: 2\n",
        "      output_csv_path: standard_data.csv\n",
        "      call_option:\n",
        "        temperature: 1.6\n",
        "        presence_penalty: 2\n",
        "  source_type: machine_generated\n",
        "'''\n",
        "\n",
        "with open('test_data_generator.yaml', 'w') as file:\n",
        "    file.write(yaml_content)\n",
        "\n",
        "# Generate data with YiVal\n",
        "!poetry run yival run test_data_generator.yaml\n",
        "\n",
        "# Visualize data\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"standard_data.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "hQ1dl-xoPaGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Variations**\n",
        "\n",
        "Variations are import in yival , different vairations mean different experiment environments.\n",
        "\n",
        "Here we support two types of llm as student , and compare their capacity in translation\n",
        "1. gpt-3.5-turbo\n",
        "2. llama2-13b\n",
        "\n",
        "```yaml\n",
        "variations:\n",
        "  - name : model_name\n",
        "    variations:\n",
        "      - instantiated_value: gpt-3.5-turbo\n",
        "        value: gpt-3.5-turbo\n",
        "        value_type: str\n",
        "        variation_id: null\n",
        "\n",
        "      - instantiated_value: replicate/a16z-infra/llama-2-13b-chat:9dff94b1bed5af738655d4a7cbcdcde2bd503aa85c94334fe1f42af7f3dd5ee3\n",
        "        value: a16z-infra/llama-2-13b-chat:9dff94b1bed5af738655d4a7cbcdcde2bd503aa85c94334fe1f42af7f3dd5ee3\n",
        "        value_type: str\n",
        "        variation_id: null\n",
        "```"
      ],
      "metadata": {
        "id": "5bunQIfum6ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluator**\n",
        "\n",
        "BERT-Score uses BERT's contextual embeddings to measure semantic similarity between machine and reference translations.\n",
        "\n",
        "It's more accurate than traditional metrics as it captures semantic meaning, making it a good evaluation metric for translation tasks.\n",
        "\n",
        "Here we use [yival-bertscore-evaluator](https://github.com/YiVal/YiVal/blob/master/src/yival/evaluators/bertscore_evaluator.py) as an evaluation metric for the model's translation ability.\n",
        "\n",
        "```yaml\n",
        "evaluators:\n",
        "  - evaluator_type: individual\n",
        "    name: bertscore_evaluator\n",
        "    metric_calculators:\n",
        "      - method: AVERAGE\n",
        "    display_name: p\n",
        "    indicator: p\n",
        "  - evaluator_type: individual\n",
        "    name: bertscore_evaluator\n",
        "    metric_calculators:\n",
        "      - method: AVERAGE\n",
        "    display_name: r\n",
        "    indicator: r\n",
        "  - evaluator_type: individual\n",
        "    name: bertscore_evaluator\n",
        "    metric_calculators:\n",
        "      - method: AVERAGE\n",
        "    display_name: f\n",
        "    indicator: f\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9RNK1PIKnZ_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **YiVal Translate_Quiz**"
      ],
      "metadata": {
        "id": "AmbSYL87hMKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['ngrok']='true'\n",
        "!poetry run ngrok config add-authtoken 2UK3G7MKgDqCqDnu36njaaE02bZ_7FqvcqBke5hbpgHjizoo7\n",
        "!poetry run yival run /content/YiVal/demo/configs/translate_quiz.yml --output_path quiz100.pkl"
      ],
      "metadata": {
        "id": "EVz9bzklf82N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://github.com/crazycth/pictures/assets/55043304/e6c145b9-ebbf-4445-9d8d-59adb1f9776a)\n",
        "\n",
        "It's obvious that llama2 can't handle chinese translation really well without finetune , so next we will **finetune** llama2 to make it more powerful"
      ],
      "metadata": {
        "id": "S5DkpkRkh76A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetune llama2 with replicate api\n",
        "\n",
        "We provide really easy way for you to finetune llama2\n",
        "\n",
        "the data can be source from data that fit evaluator condition , or data with expected_value generated by GPT-4\n",
        "\n",
        "You can check our [replicate_finetune](https://github.com/YiVal/YiVal/blob/master/src/yival/dataset/replicate_finetune_utils.py) for more detail\n",
        "\n",
        "you will get a model_name after finetune , you can call finetuned model with this model_name through replicate"
      ],
      "metadata": {
        "id": "pu80wCcOiW9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!poetry run python /content/YiVal/src/yival/dataset/replicate_finetune_utils.py"
      ],
      "metadata": {
        "id": "HQjLBSHSh_sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Finetuned model\n",
        "\n",
        "Add new model_name to translate_quiz.yml\n",
        "```yml\n",
        "variations:\n",
        "  - name : model_name\n",
        "    variations:\n",
        "      - instantiated_value: gpt-3.5-turbo\n",
        "        value: gpt-3.5-turbo\n",
        "        value_type: str\n",
        "        variation_id: null\n",
        "\n",
        "      - instantiated_value: replicate/a16z-infra/llama-2-13b-chat:9dff94b1bed5af738655d4a7cbcdcde2bd503aa85c94334fe1f42af7f3dd5ee3\n",
        "        value: a16z-infra/llama-2-13b-chat:9dff94b1bed5af738655d4a7cbcdcde2bd503aa85c94334fe1f42af7f3dd5ee3\n",
        "        value_type: str\n",
        "        variation_id: null\n",
        "      \n",
        "      - instantiated_value: new_model_name\n",
        "        value: new_model_name\n",
        "        value_type: str\n",
        "        variation_id: null\n",
        "      \n",
        "```\n",
        "\n",
        "Fine-tuning with Replicate\n",
        "For demo use cases, we only use **400** examples, and fine-tuning with 10 epochs, using Replicate API. Even with limited data, we saw significant performance improvement on llama2 regarding English-to-Chinese translation.\n",
        "- bertscore-p 0.419 -> 0.445 (**+6.2%**)\n",
        "- bertscore-r 0.592 -> 0.611 (**+3.2%**)\n",
        "- bertscore-f 0.489 -> 0.514 (**+5.1%**)\n",
        "\n",
        "![image](https://github.com/crazycth/pictures/assets/55043304/898a8812-bbd9-4d3d-92fa-1a8c6b433e8c)"
      ],
      "metadata": {
        "id": "oebGits8iZWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!poetry run yival run /content/YiVal/demo/configs/translate_quiz.yml --output_path quiz100.pkl"
      ],
      "metadata": {
        "id": "iF32JabAib00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning results locally\n",
        "We also conduct a more complete fine-tuning locally with [EMNLP 2020 translation dataset](https://statmt.org/wmt20/translation-task.html).\n",
        "\n",
        "We finetune our modal locally with [yival-sft-trainer](https://github.com/YiVal/YiVal/blob/add_conditioin_for_trainer/src/yival/finetune/sft_trainer.py) with 8 1080Ti and train for 8 hours.\n",
        "\n",
        "For the same 400 test data sample, we achieved much better performance.\n",
        "- bertscore-p 0.516 -> 0.835 (**+61.8%**)\n",
        "- bertscore-r 0.653 -> 0.828 (**+27.0%**)\n",
        "- bertscore-f 0.575 -> 0.831 (**+44.5%**)\n",
        "\n",
        "Also, we see after fine-tuning, our new llama2 model can achieve **comparable performance** as gpt-3.5.\n",
        "\n",
        "![**Model performance comparison**](https://github.com/KyleChen400/YiVal/assets/42785676/a62782d6-1523-408c-a5ce-f7069c720f68)"
      ],
      "metadata": {
        "id": "0IluU2XXiioT"
      }
    }
  ]
}